{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset\n",
    "\n",
    "Load the dataset. The dataset is composed of the subject information sheet as well as 16 different data collection sessions and 24 subjects. Each session is for a different activity type: ['dws', 'ups', 'std', 'sit', 'jog', 'wlk']. The device data is time-series data for each subject. Each avtivity session has its own folder containing the time series data for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframe shape:  (1412865, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "subjects_data_file = 'dataset/data_subjects_info.csv'\n",
    "device_data_dir = 'dataset/A_DeviceMotion_data/'\n",
    "\n",
    "def get_all_dataset_paths(input_dir):\n",
    "    input_files = []\n",
    "    for dirs, subdirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                input_files.append(os.path.join(dirs, file))\n",
    "    return input_files\n",
    "\n",
    "def load_dataset(paths, meta):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for p in paths:\n",
    "        c_dir, c_file = p.split('/')[-2], p.split('/')[-1]\n",
    "        c_cat, c_ses = c_dir.split('_')[-2], c_dir.split('_')[-1]\n",
    "        c_sub = c_file.split('_')[-1].split('.')[-2]\n",
    "\n",
    "        tdf = pd.read_csv(p, encoding='utf-8')\n",
    "\n",
    "        tdf = tdf.assign(subject_id = int(c_sub))\n",
    "        tdf = tdf.assign(session_id = int(c_ses))\n",
    "        tdf = tdf.assign(category = str(c_cat))\n",
    "        tdf = tdf.assign(age = int(meta.age[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(gender = int(meta.gender[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(height = int(meta.height[int(c_sub) - 1]))\n",
    "        tdf = tdf.assign(weight = int(meta.weight[int(c_sub) - 1]))\n",
    "\n",
    "        df = pd.concat([df, tdf])\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "subject_df = pd.DataFrame(pd.read_csv(subjects_data_file, encoding='utf-8'))\n",
    "all_ds_paths = get_all_dataset_paths(device_data_dir)\n",
    "data_frame = load_dataset(all_ds_paths, subject_df)\n",
    "\n",
    "print('[INFO] Dataframe shape: ', data_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "The Unnamed 0, weight, height, subject id, session id, age, gender columns are removed as they are not used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_frame.copy()\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.drop('subject_id', axis=1, inplace=True)\n",
    "df.drop('session_id', axis=1, inplace=True)\n",
    "df.drop('age', axis=1, inplace=True)\n",
    "df.drop('gender', axis=1, inplace=True)\n",
    "df.drop('height', axis=1, inplace=True)\n",
    "df.drop('weight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Encoding the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataframe shape:  (1412865, 13)\n",
      "[INFO] Dataframe columns:  Index(['attitude.roll', 'attitude.pitch', 'attitude.yaw', 'gravity.x',\n",
      "       'gravity.y', 'gravity.z', 'rotationRate.x', 'rotationRate.y',\n",
      "       'rotationRate.z', 'userAcceleration.x', 'userAcceleration.y',\n",
      "       'userAcceleration.z', 'code'],\n",
      "      dtype='object')\n",
      "[INFO] Dataframe labels:  ['dws' 'jog' 'sit' 'std' 'ups' 'wlk']\n",
      "[INFO] Dataframe head:     attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
      "0      -2.116381       -1.077507     -2.261502  -0.404768   0.880780   \n",
      "1      -2.148154       -1.049759     -2.284278  -0.417081   0.867303   \n",
      "2      -2.153824       -1.026749     -2.297008  -0.432082   0.855621   \n",
      "3      -2.142509       -1.012749     -2.290595  -0.445311   0.848291   \n",
      "4      -2.130486       -1.007262     -2.274149  -0.452661   0.845372   \n",
      "\n",
      "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
      "0   0.245713       -1.264215       -1.027909       -0.947909   \n",
      "1   0.271686       -1.162024       -0.269118       -0.848823   \n",
      "2   0.284961       -0.665042        0.520170       -0.726722   \n",
      "3   0.286507       -0.079809        0.055322       -0.604534   \n",
      "4   0.283600        0.456097       -0.186877       -0.441315   \n",
      "\n",
      "   userAcceleration.x  userAcceleration.y  userAcceleration.z  code  \n",
      "0            0.282683           -0.254346           -0.407670     0  \n",
      "1            0.256712            0.079154           -0.560291     0  \n",
      "2            0.253600            0.346680           -0.463275     0  \n",
      "3            0.411818            0.459372           -0.510293     0  \n",
      "4            0.311594            0.477305           -0.925049     0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit(df['category'])\n",
    "df['code'] = le.transform(df['category'])\n",
    "df.drop('category', axis=1, inplace=True)\n",
    "\n",
    "print('[INFO] Dataframe shape: ', df.shape)\n",
    "print('[INFO] Dataframe columns: ', df.columns)\n",
    "print('[INFO] Dataframe labels: ', labels.classes_)\n",
    "print('[INFO] Dataframe head: ', df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_train shape:  (1130292, 12)\n",
      "[INFO] X_test shape:  (282573, 12)\n",
      "[INFO] y_train shape:  (1130292, 1)\n",
      "[INFO] y_test shape:  (282573, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_cols = df.iloc[:, 0:12]\n",
    "y_cols = df.iloc[:, 12:13]\n",
    "\n",
    "# Do not shuffle as the data is time series\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_cols, y_cols, test_size=0.2, shuffle=False)\n",
    "print(\"[INFO] X_train shape: \", X_train.shape)\n",
    "print(\"[INFO] X_test shape: \", X_test.shape)\n",
    "print(\"[INFO] y_train shape: \", y_train.shape)\n",
    "print(\"[INFO] y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tx shape:  (113015, 150, 12)\n",
      "[INFO] ty shape:  (113015,)\n",
      "[INFO] vx shape:  (28243, 150, 12)\n",
      "[INFO] vy shape:  (28243,)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "WINDOW_SIZE = 150\n",
    "STRIDE = 10\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 12\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS_SIZE = 10\n",
    "\n",
    "def sliding_window(x, y, length, stride):\n",
    "    seq_x, seq_y = [], []\n",
    "    data_len = len(x)\n",
    "\n",
    "    for i in range(0, data_len - length + 1, stride):\n",
    "        input_sec = x.iloc[i:i + length]\n",
    "        target_sec = y.iloc[i:i + length]\n",
    "        target = mode(target_sec)[0][0]\n",
    "        seq_x.append(input_sec)\n",
    "        seq_y.append(target)\n",
    "    return np.array(seq_x), np.array(seq_y)\n",
    "\n",
    "tx, ty = sliding_window(X_train, y_train, WINDOW_SIZE, STRIDE)\n",
    "vx, vy = sliding_window(X_test, y_test, WINDOW_SIZE, STRIDE)\n",
    "print(\"[INFO] tx shape: \", tx.shape)\n",
    "print(\"[INFO] ty shape: \", ty.shape)\n",
    "print(\"[INFO] vx shape: \", vx.shape)\n",
    "print(\"[INFO] vy shape: \", vy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tty shape:  (113015, 6)\n",
      "[INFO] vvy shape:  (28243, 6)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "tty = to_categorical(ty, num_classes=NUM_CLASSES)\n",
    "vvy = to_categorical(vy, num_classes=NUM_CLASSES)\n",
    "\n",
    "print(\"[INFO] tty shape: \", tty.shape)\n",
    "print(\"[INFO] vvy shape: \", vvy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Analisys\n",
    "\n",
    "This is where the model comes in, either use LSTM based model or 2d CNNJk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 148, 32)           1184      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 74, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 74, 32)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 72, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 36, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 36, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               230500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238498 (931.63 KB)\n",
      "Trainable params: 238498 (931.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Softmax\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# play with model structure here\n",
    "model.add(Input((WINDOW_SIZE, NUM_FEATURES)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.2057 - accuracy: 0.9343 - val_loss: 0.0189 - val_accuracy: 0.9986\n",
      "Epoch 2/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0223 - val_accuracy: 0.9930\n",
      "Epoch 3/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.0238 - val_accuracy: 0.9915\n",
      "Epoch 4/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0258 - val_accuracy: 0.9917\n",
      "Epoch 6/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.0068 - val_accuracy: 0.9985\n",
      "Epoch 7/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 8/10\n",
      "1131/1131 [==============================] - 9s 8ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "1131/1131 [==============================] - 10s 8ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0178 - val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "1131/1131 [==============================] - 10s 9ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0130 - val_accuracy: 0.9978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tx, tty, epochs=EPOCHS_SIZE, batch_size=BATCH_SIZE, validation_data=(vx, vvy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 1s 2ms/step - loss: 0.0130 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01295988168567419, 0.9978047609329224]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(vx, vvy, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883/883 [==============================] - 1s 1ms/step\n",
      "(28243,)\n",
      "(28243,)\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "[[    0     0     0     0]\n",
      " [    0  5768     1     0]\n",
      " [   21    22 22413    18]\n",
      " [    0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(vx)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(vvy, axis=1)\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_true.shape)\n",
    "\n",
    "print(np.max(y_pred))\n",
    "print(np.min(y_pred))\n",
    "\n",
    "print(np.max(y_true))\n",
    "print(np.min(y_true))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
